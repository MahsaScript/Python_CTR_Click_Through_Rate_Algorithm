{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh5F8PHlSixd"
      },
      "source": [
        "## MODEL DEVELOPMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIRBAY7nSixt"
      },
      "outputs": [],
      "source": [
        "# import all necessary packages\n",
        "\n",
        "# to connect W&B platform\n",
        "import wandb\n",
        "\n",
        "# to handle dataframe\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# to split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to train model\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeG0O10oSix5"
      },
      "source": [
        "### Main Purpose of CTR Prediction Model\n",
        "\n",
        "The main purpose of CTR prediction is to enhance the performance of online advertising and content recommendation systems, leading to increased revenue, better user experiences, and more effective marketing strategies. Accurate CTR prediction allows organizations to optimize their digital interactions with users, resulting in tangible benefits for both businesses and consumers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOZDDh0rSix7"
      },
      "source": [
        "### Algorithms\n",
        "\n",
        "Click-Through Rate (CTR) dataset includes only categorical features and a binary target indicating whether a click occurred (0 or 1), There are specific models that can work well for these kinds of datasets, such as; Logistic Regression, Field-Aware Factorization Machines, CatBoost, LightGBM, XGBoost, Deep learning models with embedding layers, etc. According to the research, the Catboost algorithm can be a more suitable algorithm than other algorithms for this purpose.\n",
        "\n",
        "\n",
        "#### Catboost Algorithm\n",
        "CatBoost is a supervised machine learning technique employed within the Train Using AutoML tool. It relies on decision trees for tasks involving classification and regression. The name CatBoost signifies its primary attributes: the ability to handle categorical data (represented by \"Cat\") and its utilization of gradient boosting (signified by \"Boost\").\n",
        "\n",
        "Advantages;\n",
        "* Handle categorical features without requiring one-hot encoding or other transformations.\n",
        "* Automatically scales the gradient magnitudes of numerical features and the target variable.\n",
        "* Includes built-in regularization to prevent overfitting. It includes embedded methods to avoid overfitting.\n",
        "* Less preprocessing with no encoding and handling missing values.\n",
        "* Has both CPU and GPU implementations. The GPU implementation allows for much faster training and is faster than both state-of-the-art open-source implementations.\n",
        "\n",
        "Because of the advantages above, Catboost was chosen for this study. CatBoost is a good choice, but the best model depends on your specific dataset and experiments. It's always a good idea to compare CatBoost's performance with other models like LightGBM, XGBoost, and Factorization Machines to find the optimal model for your task.\n",
        "\n",
        "CatBoost is based on gradient boosted decision trees. During training, a set of decision trees is built consecutively. Each successive tree is built with reduced loss compared to the previous trees. https://catboost.ai/en/docs/concepts/algorithm-main-stages\n",
        "\n",
        "DON'T FORGET⚠ Cross-validation is an important technic to find best performed model, especially if you have a restricted number of data and need a more generalized model. CV will help you identify the most suitable model for your CTR prediction. In this notebook, CV is not applied, but the Catboost library also includes cv methods. (*from catboost import cv*)\n",
        "\n",
        "\n",
        "Please check the Catboost paper: https://arxiv.org/pdf/1810.11363.pdf\n",
        "\n",
        "Please check the documentation of Catboost: https://catboost.ai/en/docs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xQS8gM4Six-"
      },
      "outputs": [],
      "source": [
        "# connect wandb with your key\n",
        "\n",
        "# wandb.login(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "# wandb login e7af045db59ef2d253743f547f333040a785e5ce\n",
        "# OR\n",
        "# wandb.login(api_key=\"e7af045db59ef2d253743f547f333040a785e5ce\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AL17SVTSiyA"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "For the Catboost algorithm no need to apply encoding techniques such as one-hot encoding, label encoding, or target encoding (encoding categorical variables for regression problems) as a preprocess. It is handled by the algorithm implicitly.\n",
        "\n",
        "But to prepare the dataset for the model training;\n",
        "* Datatypes of the loaded dataset will be indicated again,\n",
        "* The features \"id\" and \"hour\" will be removed, because hour and day info are already extracted from the hour column,\n",
        "* Target column \"click\" is removed from the feature dataset and X and y datasets are created,\n",
        "* Train, validation, and test sets are prepared according to percentages; 80%, 10%, 10%.\n",
        "\n",
        "#### Important Features Selection\n",
        "You can remove uninformative or redundant categorical features by domain knowledge, and correlation techniques before training. But if you couldn't detect correlated columns in the dataset explicitly, don't worry, Catboost offers regularization parameters (L1, L2) that can help reduce the impact of less important features during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2HfquOOSiyC"
      },
      "outputs": [],
      "source": [
        "# give datatypes\n",
        "\n",
        "dtype={'id': np.dtype(int),\n",
        "    'click': np.dtype(int),\n",
        "    'hour': np.dtype(str),\n",
        "    'C1': np.dtype(str),\n",
        "    'banner_pos': np.dtype(str),\n",
        "    'site_id': np.dtype(str),\n",
        "    'site_domain': np.dtype(str),\n",
        "    'site_category': np.dtype(str),\n",
        "    'app_id': np.dtype(str),\n",
        "    'app_domain': np.dtype(str),\n",
        "    'app_category': np.dtype(str),\n",
        "    'device_id': np.dtype(str),\n",
        "    'device_ip': np.dtype(str),\n",
        "    'device_model': np.dtype(str),\n",
        "    'device_type': np.dtype(str),\n",
        "    'device_conn_type': np.dtype(str),\n",
        "    'C14': np.dtype(str),\n",
        "    'C15': np.dtype(str),\n",
        "    'C16': np.dtype(str),\n",
        "    'C17': np.dtype(str),\n",
        "    'C18': np.dtype(str),\n",
        "    'C19': np.dtype(str),\n",
        "    'C20': np.dtype(str),\n",
        "    'C21':np.dtype(str),\n",
        "    'hour_of_day': np.dtype(str),\n",
        "    'day_of_week': np.dtype(str),\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OFN_hi6SiyF"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "\n",
        "df = pd.read_csv('/dataset/training-dataset-10000.csv',dtype=dtype,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k332NiYYSiyH",
        "outputId": "b5c43dfa-4dcb-4521-e853-6cd20d078e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 26 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   id                10000 non-null  uint64\n",
            " 1   click             10000 non-null  int64 \n",
            " 2   hour              10000 non-null  object\n",
            " 3   C1                10000 non-null  object\n",
            " 4   banner_pos        10000 non-null  object\n",
            " 5   site_id           10000 non-null  object\n",
            " 6   site_domain       10000 non-null  object\n",
            " 7   site_category     10000 non-null  object\n",
            " 8   app_id            10000 non-null  object\n",
            " 9   app_domain        10000 non-null  object\n",
            " 10  app_category      10000 non-null  object\n",
            " 11  device_id         10000 non-null  object\n",
            " 12  device_ip         10000 non-null  object\n",
            " 13  device_model      10000 non-null  object\n",
            " 14  device_type       10000 non-null  object\n",
            " 15  device_conn_type  10000 non-null  object\n",
            " 16  C14               10000 non-null  object\n",
            " 17  C15               10000 non-null  object\n",
            " 18  C16               10000 non-null  object\n",
            " 19  C17               10000 non-null  object\n",
            " 20  C18               10000 non-null  object\n",
            " 21  C19               10000 non-null  object\n",
            " 22  C20               10000 non-null  object\n",
            " 23  C21               10000 non-null  object\n",
            " 24  hour_of_day       10000 non-null  object\n",
            " 25  day_of_week       10000 non-null  object\n",
            "dtypes: int64(1), object(24), uint64(1)\n",
            "memory usage: 2.0+ MB\n"
          ]
        }
      ],
      "source": [
        "# check non-null columns and datatypes\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4fqNx3oSiyN"
      },
      "outputs": [],
      "source": [
        "# drop unnecessary columns\n",
        "\n",
        "df.drop(columns=[\"id\", \"hour\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tfGwn1ZSiyP",
        "outputId": "a2c3bd0e-2ab0-452b-e9a6-308cae3b48f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C1</th>\n",
              "      <th>banner_pos</th>\n",
              "      <th>site_id</th>\n",
              "      <th>site_domain</th>\n",
              "      <th>site_category</th>\n",
              "      <th>app_id</th>\n",
              "      <th>app_domain</th>\n",
              "      <th>app_category</th>\n",
              "      <th>device_id</th>\n",
              "      <th>device_ip</th>\n",
              "      <th>...</th>\n",
              "      <th>C14</th>\n",
              "      <th>C15</th>\n",
              "      <th>C16</th>\n",
              "      <th>C17</th>\n",
              "      <th>C18</th>\n",
              "      <th>C19</th>\n",
              "      <th>C20</th>\n",
              "      <th>C21</th>\n",
              "      <th>hour_of_day</th>\n",
              "      <th>day_of_week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>1fbe01fe</td>\n",
              "      <td>f3845767</td>\n",
              "      <td>28905ebd</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>431b3174</td>\n",
              "      <td>...</td>\n",
              "      <td>15704</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1722</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>3695113d</td>\n",
              "      <td>8a9459c0</td>\n",
              "      <td>3e814130</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>e7ab261c</td>\n",
              "      <td>...</td>\n",
              "      <td>20366</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2333</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>100103</td>\n",
              "      <td>157</td>\n",
              "      <td>0</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>543a539e</td>\n",
              "      <td>c7ca3108</td>\n",
              "      <td>3e814130</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>d0aa00c7</td>\n",
              "      <td>...</td>\n",
              "      <td>20352</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2333</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>-1</td>\n",
              "      <td>157</td>\n",
              "      <td>0</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>1fbe01fe</td>\n",
              "      <td>f3845767</td>\n",
              "      <td>28905ebd</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>ef85aaad</td>\n",
              "      <td>...</td>\n",
              "      <td>15705</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1722</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>100084</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>85f751fd</td>\n",
              "      <td>c4e18dd6</td>\n",
              "      <td>50e219e0</td>\n",
              "      <td>1779deee</td>\n",
              "      <td>2347f47a</td>\n",
              "      <td>f95efa07</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>ba92cd0f</td>\n",
              "      <td>...</td>\n",
              "      <td>20596</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2161</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>157</td>\n",
              "      <td>0</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>85f751fd</td>\n",
              "      <td>c4e18dd6</td>\n",
              "      <td>50e219e0</td>\n",
              "      <td>febd1138</td>\n",
              "      <td>82e27996</td>\n",
              "      <td>0f2161f8</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>8f642135</td>\n",
              "      <td>...</td>\n",
              "      <td>21611</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2480</td>\n",
              "      <td>3</td>\n",
              "      <td>299</td>\n",
              "      <td>100111</td>\n",
              "      <td>61</td>\n",
              "      <td>23</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>85f751fd</td>\n",
              "      <td>c4e18dd6</td>\n",
              "      <td>50e219e0</td>\n",
              "      <td>9c13b419</td>\n",
              "      <td>2347f47a</td>\n",
              "      <td>f95efa07</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>d30e5a48</td>\n",
              "      <td>...</td>\n",
              "      <td>23161</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2667</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>-1</td>\n",
              "      <td>221</td>\n",
              "      <td>23</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>85f751fd</td>\n",
              "      <td>c4e18dd6</td>\n",
              "      <td>50e219e0</td>\n",
              "      <td>9c13b419</td>\n",
              "      <td>2347f47a</td>\n",
              "      <td>f95efa07</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>9cf8ab70</td>\n",
              "      <td>...</td>\n",
              "      <td>23160</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2667</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>-1</td>\n",
              "      <td>221</td>\n",
              "      <td>23</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1005</td>\n",
              "      <td>1</td>\n",
              "      <td>e151e245</td>\n",
              "      <td>7e091613</td>\n",
              "      <td>f028772b</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>10dcdfb1</td>\n",
              "      <td>...</td>\n",
              "      <td>23723</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2716</td>\n",
              "      <td>3</td>\n",
              "      <td>47</td>\n",
              "      <td>-1</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>1fbe01fe</td>\n",
              "      <td>f3845767</td>\n",
              "      <td>28905ebd</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>372c853c</td>\n",
              "      <td>...</td>\n",
              "      <td>22257</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2545</td>\n",
              "      <td>0</td>\n",
              "      <td>431</td>\n",
              "      <td>100084</td>\n",
              "      <td>221</td>\n",
              "      <td>23</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        C1 banner_pos   site_id site_domain site_category    app_id  \\\n",
              "0     1005          0  1fbe01fe    f3845767      28905ebd  ecad2386   \n",
              "1     1005          0  3695113d    8a9459c0      3e814130  ecad2386   \n",
              "2     1005          0  543a539e    c7ca3108      3e814130  ecad2386   \n",
              "3     1005          0  1fbe01fe    f3845767      28905ebd  ecad2386   \n",
              "4     1005          0  85f751fd    c4e18dd6      50e219e0  1779deee   \n",
              "...    ...        ...       ...         ...           ...       ...   \n",
              "9995  1005          0  85f751fd    c4e18dd6      50e219e0  febd1138   \n",
              "9996  1005          0  85f751fd    c4e18dd6      50e219e0  9c13b419   \n",
              "9997  1005          0  85f751fd    c4e18dd6      50e219e0  9c13b419   \n",
              "9998  1005          1  e151e245    7e091613      f028772b  ecad2386   \n",
              "9999  1005          0  1fbe01fe    f3845767      28905ebd  ecad2386   \n",
              "\n",
              "     app_domain app_category device_id device_ip  ...    C14  C15 C16   C17  \\\n",
              "0      7801e8d9     07d7df22  a99f214a  431b3174  ...  15704  320  50  1722   \n",
              "1      7801e8d9     07d7df22  a99f214a  e7ab261c  ...  20366  320  50  2333   \n",
              "2      7801e8d9     07d7df22  a99f214a  d0aa00c7  ...  20352  320  50  2333   \n",
              "3      7801e8d9     07d7df22  a99f214a  ef85aaad  ...  15705  320  50  1722   \n",
              "4      2347f47a     f95efa07  a99f214a  ba92cd0f  ...  20596  320  50  2161   \n",
              "...         ...          ...       ...       ...  ...    ...  ...  ..   ...   \n",
              "9995   82e27996     0f2161f8  a99f214a  8f642135  ...  21611  320  50  2480   \n",
              "9996   2347f47a     f95efa07  a99f214a  d30e5a48  ...  23161  320  50  2667   \n",
              "9997   2347f47a     f95efa07  a99f214a  9cf8ab70  ...  23160  320  50  2667   \n",
              "9998   7801e8d9     07d7df22  a99f214a  10dcdfb1  ...  23723  320  50  2716   \n",
              "9999   7801e8d9     07d7df22  a99f214a  372c853c  ...  22257  320  50  2545   \n",
              "\n",
              "     C18  C19     C20  C21 hour_of_day day_of_week  \n",
              "0      0   35      -1   79           0     Tuesday  \n",
              "1      0   39  100103  157           0     Tuesday  \n",
              "2      0   39      -1  157           0     Tuesday  \n",
              "3      0   35  100084   79           0     Tuesday  \n",
              "4      0   35      -1  157           0     Tuesday  \n",
              "...   ..  ...     ...  ...         ...         ...  \n",
              "9995   3  299  100111   61          23    Thursday  \n",
              "9996   0   47      -1  221          23    Thursday  \n",
              "9997   0   47      -1  221          23    Thursday  \n",
              "9998   3   47      -1   23          23    Thursday  \n",
              "9999   0  431  100084  221          23    Thursday  \n",
              "\n",
              "[10000 rows x 23 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create feature df (X) and target df (y)\n",
        "# X: Features, y: Target\n",
        "\n",
        "X=df.drop(['click'],axis=1)\n",
        "y=df['click']\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cftHl1T6SiyQ"
      },
      "outputs": [],
      "source": [
        "# split dataset for training\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42) # 80% train\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) # 10% test, 10% valid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt6VbA6sSiyR"
      },
      "source": [
        "While the 80-10-10 split is common, it's not set in stone. For smaller datasets, you might want to allocate a larger portion to training. In some cases, you might even consider a 70-15-15 split or variations depending on your specific needs and constraints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf_4g3iKSiyS",
        "outputId": "417dd005-4f0d-493a-b04a-1ace5a9e2ac7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C1</th>\n",
              "      <th>banner_pos</th>\n",
              "      <th>site_id</th>\n",
              "      <th>site_domain</th>\n",
              "      <th>site_category</th>\n",
              "      <th>app_id</th>\n",
              "      <th>app_domain</th>\n",
              "      <th>app_category</th>\n",
              "      <th>device_id</th>\n",
              "      <th>device_ip</th>\n",
              "      <th>...</th>\n",
              "      <th>C14</th>\n",
              "      <th>C15</th>\n",
              "      <th>C16</th>\n",
              "      <th>C17</th>\n",
              "      <th>C18</th>\n",
              "      <th>C19</th>\n",
              "      <th>C20</th>\n",
              "      <th>C21</th>\n",
              "      <th>hour_of_day</th>\n",
              "      <th>day_of_week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9254</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>85f751fd</td>\n",
              "      <td>c4e18dd6</td>\n",
              "      <td>50e219e0</td>\n",
              "      <td>1cc958a2</td>\n",
              "      <td>2347f47a</td>\n",
              "      <td>f95efa07</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>2022a4c8</td>\n",
              "      <td>...</td>\n",
              "      <td>23804</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2726</td>\n",
              "      <td>3</td>\n",
              "      <td>803</td>\n",
              "      <td>100148</td>\n",
              "      <td>229</td>\n",
              "      <td>5</td>\n",
              "      <td>Thursday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1561</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>1fbe01fe</td>\n",
              "      <td>f3845767</td>\n",
              "      <td>28905ebd</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>a4afe726</td>\n",
              "      <td>...</td>\n",
              "      <td>15702</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1722</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>79</td>\n",
              "      <td>10</td>\n",
              "      <td>Wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1670</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>85f751fd</td>\n",
              "      <td>c4e18dd6</td>\n",
              "      <td>50e219e0</td>\n",
              "      <td>e9739828</td>\n",
              "      <td>df32afa9</td>\n",
              "      <td>cef3e649</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>fe75d0c7</td>\n",
              "      <td>...</td>\n",
              "      <td>21769</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2507</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>157</td>\n",
              "      <td>11</td>\n",
              "      <td>Wednesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6087</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>93eaba74</td>\n",
              "      <td>7687a86e</td>\n",
              "      <td>3e814130</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>26b8bb1b</td>\n",
              "      <td>...</td>\n",
              "      <td>17654</td>\n",
              "      <td>300</td>\n",
              "      <td>250</td>\n",
              "      <td>1994</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>-1</td>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>Monday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6669</th>\n",
              "      <td>1005</td>\n",
              "      <td>1</td>\n",
              "      <td>856e6d3f</td>\n",
              "      <td>58a89a43</td>\n",
              "      <td>f028772b</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>ab39bdf7</td>\n",
              "      <td>...</td>\n",
              "      <td>19772</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2227</td>\n",
              "      <td>0</td>\n",
              "      <td>935</td>\n",
              "      <td>-1</td>\n",
              "      <td>48</td>\n",
              "      <td>22</td>\n",
              "      <td>Monday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5734</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>85f751fd</td>\n",
              "      <td>c4e18dd6</td>\n",
              "      <td>50e219e0</td>\n",
              "      <td>090d3a47</td>\n",
              "      <td>0654b444</td>\n",
              "      <td>0f2161f8</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>b4b35bee</td>\n",
              "      <td>...</td>\n",
              "      <td>17212</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1887</td>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>100194</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>Sunday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>1005</td>\n",
              "      <td>1</td>\n",
              "      <td>178a7b89</td>\n",
              "      <td>b4598159</td>\n",
              "      <td>f028772b</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>7ab43b94</td>\n",
              "      <td>...</td>\n",
              "      <td>19771</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>2227</td>\n",
              "      <td>0</td>\n",
              "      <td>679</td>\n",
              "      <td>100081</td>\n",
              "      <td>48</td>\n",
              "      <td>7</td>\n",
              "      <td>Sunday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>1fbe01fe</td>\n",
              "      <td>f3845767</td>\n",
              "      <td>28905ebd</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>0fa21480</td>\n",
              "      <td>...</td>\n",
              "      <td>15706</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1722</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>-1</td>\n",
              "      <td>79</td>\n",
              "      <td>11</td>\n",
              "      <td>Sunday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>1005</td>\n",
              "      <td>0</td>\n",
              "      <td>85f751fd</td>\n",
              "      <td>c4e18dd6</td>\n",
              "      <td>50e219e0</td>\n",
              "      <td>2d869bee</td>\n",
              "      <td>d9b5648e</td>\n",
              "      <td>0f2161f8</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>1ca2d148</td>\n",
              "      <td>...</td>\n",
              "      <td>20751</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1895</td>\n",
              "      <td>0</td>\n",
              "      <td>681</td>\n",
              "      <td>100028</td>\n",
              "      <td>101</td>\n",
              "      <td>19</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>1005</td>\n",
              "      <td>1</td>\n",
              "      <td>e151e245</td>\n",
              "      <td>7e091613</td>\n",
              "      <td>f028772b</td>\n",
              "      <td>ecad2386</td>\n",
              "      <td>7801e8d9</td>\n",
              "      <td>07d7df22</td>\n",
              "      <td>a99f214a</td>\n",
              "      <td>0be07df1</td>\n",
              "      <td>...</td>\n",
              "      <td>17264</td>\n",
              "      <td>320</td>\n",
              "      <td>50</td>\n",
              "      <td>1872</td>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>-1</td>\n",
              "      <td>23</td>\n",
              "      <td>11</td>\n",
              "      <td>Tuesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        C1 banner_pos   site_id site_domain site_category    app_id  \\\n",
              "9254  1005          0  85f751fd    c4e18dd6      50e219e0  1cc958a2   \n",
              "1561  1005          0  1fbe01fe    f3845767      28905ebd  ecad2386   \n",
              "1670  1005          0  85f751fd    c4e18dd6      50e219e0  e9739828   \n",
              "6087  1005          0  93eaba74    7687a86e      3e814130  ecad2386   \n",
              "6669  1005          1  856e6d3f    58a89a43      f028772b  ecad2386   \n",
              "...    ...        ...       ...         ...           ...       ...   \n",
              "5734  1005          0  85f751fd    c4e18dd6      50e219e0  090d3a47   \n",
              "5191  1005          1  178a7b89    b4598159      f028772b  ecad2386   \n",
              "5390  1005          0  1fbe01fe    f3845767      28905ebd  ecad2386   \n",
              "860   1005          0  85f751fd    c4e18dd6      50e219e0  2d869bee   \n",
              "7270  1005          1  e151e245    7e091613      f028772b  ecad2386   \n",
              "\n",
              "     app_domain app_category device_id device_ip  ...    C14  C15  C16   C17  \\\n",
              "9254   2347f47a     f95efa07  a99f214a  2022a4c8  ...  23804  320   50  2726   \n",
              "1561   7801e8d9     07d7df22  a99f214a  a4afe726  ...  15702  320   50  1722   \n",
              "1670   df32afa9     cef3e649  a99f214a  fe75d0c7  ...  21769  320   50  2507   \n",
              "6087   7801e8d9     07d7df22  a99f214a  26b8bb1b  ...  17654  300  250  1994   \n",
              "6669   7801e8d9     07d7df22  a99f214a  ab39bdf7  ...  19772  320   50  2227   \n",
              "...         ...          ...       ...       ...  ...    ...  ...  ...   ...   \n",
              "5734   0654b444     0f2161f8  a99f214a  b4b35bee  ...  17212  320   50  1887   \n",
              "5191   7801e8d9     07d7df22  a99f214a  7ab43b94  ...  19771  320   50  2227   \n",
              "5390   7801e8d9     07d7df22  a99f214a  0fa21480  ...  15706  320   50  1722   \n",
              "860    d9b5648e     0f2161f8  a99f214a  1ca2d148  ...  20751  320   50  1895   \n",
              "7270   7801e8d9     07d7df22  a99f214a  0be07df1  ...  17264  320   50  1872   \n",
              "\n",
              "     C18  C19     C20  C21 hour_of_day day_of_week  \n",
              "9254   3  803  100148  229           5    Thursday  \n",
              "1561   0   35      -1   79          10   Wednesday  \n",
              "1670   0   35      -1  157          11   Wednesday  \n",
              "6087   2   39      -1   33           6      Monday  \n",
              "6669   0  935      -1   48          22      Monday  \n",
              "...   ..  ...     ...  ...         ...         ...  \n",
              "5734   3   39  100194   23          17      Sunday  \n",
              "5191   0  679  100081   48           7      Sunday  \n",
              "5390   0   35      -1   79          11      Sunday  \n",
              "860    0  681  100028  101          19     Tuesday  \n",
              "7270   3   39      -1   23          11     Tuesday  \n",
              "\n",
              "[8000 rows x 23 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxlY2er2SiyT",
        "outputId": "c9cd66fa-d197-4c38-a9cf-c1fe3dd527fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9254    0\n",
              "1561    1\n",
              "1670    0\n",
              "6087    0\n",
              "6669    0\n",
              "       ..\n",
              "5734    0\n",
              "5191    0\n",
              "5390    0\n",
              "860     0\n",
              "7270    0\n",
              "Name: click, Length: 8000, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUZHsiPpSiyU"
      },
      "source": [
        "### Model Development\n",
        "\n",
        "In this section, the Catboost algorithm is used for the training process. This algorithm includes various parameters to tune in the model development process. Weight&Bias platform is used to log every iteration results in the model development.\n",
        "\n",
        "Weights & Biases (W&B) is a comprehensive platform designed to aid machine learning practitioners throughout the entire model development and experimentation process. For this study, it is used to fine tune with a range of hyperparameters, the Bayesian search method is used to find the best combination of the hyperparameters. W&B helps to see the performance metrics of each different model and helps to find the best model by comparing the important metrics.\n",
        "\n",
        "CatBoost's integration with Bayesian optimization can help you find good hyperparameter settings in fewer iterations compared to grid search or random search. It takes into account the information from previous iterations to guide the search towards areas that are likely to lead to better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMvX_fiWSiyV"
      },
      "outputs": [],
      "source": [
        "# create list to keep index of the features to put into the model\n",
        "\n",
        "cat_features = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,21,22]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ-1L-ZTSiyW"
      },
      "source": [
        "#### Which parameters can be tuned?\n",
        "\n",
        "In tuning CatBoost, there are six main hyperparameters to focus on:\n",
        "\n",
        "* **Number of Trees (iterations)**: represents the number of iterations the algorithm takes to create a more accurate model that learns from the data.\n",
        "* **Learning Rate (learning_rate)**: adjusts how much each decision tree contributes to maintain the model's overall balance and precision. A larger learning rate means each tree has a more significant impact on the model, speeding up the learning process.\n",
        "* **Depth**: “height” of decision trees. If you put high numbers, it can cause overfitting.\n",
        "* **Subsample (subsample)**: a technique used to randomly choose a fraction of the dataset when constructing each tree, which helps to reduce overfitting. It controls the fraction of the training data (rows) to be randomly sampled for each tree.\n",
        "* **Random Subspace Method (rms)**: controls the fraction of features (columns) to be randomly selected for each tree in the ensemble.\n",
        "* **Minimum Data in Leaf (min_data_in_leaf)**: determines the minimum number of samples needed to form a leaf during the tree-building process. This parameter plays a crucial role in controlling the complexity of the trees generated by the model. Larger values promote simpler trees, reducing the risk of overfitting but potentially causing underfitting. Conversely, smaller values encourage more complex trees, which can lead to overfitting.\n",
        "\n",
        "\n",
        "Other parameters which are not tuned:\n",
        "\n",
        "* **early_stopping_rounds**: determines when to stop training based on the validation loss. It specifies the number of consecutive rounds with no improvement in the validation loss before training is halted. This helps prevent overfitting and saves time. It is determined 10 for this case, you can be determined according to your resources and needs.\n",
        "* **use_best_model**: when set to True, instructs CatBoost to use the best model found during training, which is determined by monitoring the validation loss. The best model is the one with the lowest validation loss. This ensures that the model used for predictions is the one that generalizes best to unseen data.\n",
        "* **verbose**: is not an important parameter that determines how much information about the training progress and metrics is displayed in the console or log files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1PYRWyvSiyW",
        "outputId": "ef4f489f-4408-466a-b9d8-50ce27c93c4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: iph1pngh\n",
            "Sweep URL: https://wandb.ai/ftmoztl/ctr-prediction/sweeps/iph1pngh\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 45o116h1 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdepth: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 363\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.060563063844556245\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 84\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trsm: 0.9523880515949704\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.3333220993014516\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mftmoztl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/fatmaoztel/Desktop/Fatima Projects/CTR-prediction/CTR-prediction/wandb/run-20230902_122759-45o116h1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ftmoztl/ctr-prediction/runs/45o116h1' target=\"_blank\">sweet-sweep-1</a></strong> to <a href='https://wandb.ai/ftmoztl/ctr-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ftmoztl/ctr-prediction/sweeps/iph1pngh' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction/sweeps/iph1pngh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ftmoztl/ctr-prediction' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ftmoztl/ctr-prediction/sweeps/iph1pngh' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction/sweeps/iph1pngh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ftmoztl/ctr-prediction/runs/45o116h1' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction/runs/45o116h1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>average_train_loss</td><td>▁</td></tr><tr><td>average_valid_loss</td><td>▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.831</td></tr><tr><td>average_train_loss</td><td>0.39336</td></tr><tr><td>average_valid_loss</td><td>0.41416</td></tr><tr><td>f1_score</td><td>0.08649</td></tr><tr><td>precision</td><td>0.38095</td></tr><tr><td>recall</td><td>0.04878</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sweet-sweep-1</strong> at: <a href='https://wandb.ai/ftmoztl/ctr-prediction/runs/45o116h1' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction/runs/45o116h1</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230902_122759-45o116h1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ebjvcjp5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdepth: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 252\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02680990406160884\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 75\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trsm: 0.9222126250060128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.3129212854019111\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/fatmaoztel/Desktop/Fatima Projects/CTR-prediction/CTR-prediction/wandb/run-20230902_122811-ebjvcjp5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ftmoztl/ctr-prediction/runs/ebjvcjp5' target=\"_blank\">swept-sweep-2</a></strong> to <a href='https://wandb.ai/ftmoztl/ctr-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ftmoztl/ctr-prediction/sweeps/iph1pngh' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction/sweeps/iph1pngh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ftmoztl/ctr-prediction' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ftmoztl/ctr-prediction/sweeps/iph1pngh' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction/sweeps/iph1pngh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ftmoztl/ctr-prediction/runs/ebjvcjp5' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction/runs/ebjvcjp5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>average_train_loss</td><td>▁</td></tr><tr><td>average_valid_loss</td><td>▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.839</td></tr><tr><td>average_train_loss</td><td>0.39553</td></tr><tr><td>average_valid_loss</td><td>0.41397</td></tr><tr><td>f1_score</td><td>0.0904</td></tr><tr><td>precision</td><td>0.61538</td></tr><tr><td>recall</td><td>0.04878</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">swept-sweep-2</strong> at: <a href='https://wandb.ai/ftmoztl/ctr-prediction/runs/ebjvcjp5' target=\"_blank\">https://wandb.ai/ftmoztl/ctr-prediction/runs/ebjvcjp5</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230902_122811-ebjvcjp5/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yew9ct5i with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdepth: 9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 303\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04744377980734135\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmin_data_in_leaf: 56\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trsm: 0.7021187098911418\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsubsample: 0.43616456236631673\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ],
      "source": [
        "# define the sweep configuration to tune hyperparameters\n",
        "\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "\n",
        "    'metric': {\n",
        "      'name': 'average_train_loss',\n",
        "      'goal': 'minimize'\n",
        "    },\n",
        "\n",
        "    \"metric\": {\n",
        "        \"name\": \"average_valid_loss\",\n",
        "        \"goal\": \"minimize\"\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"learning_rate\": {\"min\": 0.001 , \"max\": 0.1},\n",
        "        \"depth\": {\"min\": 1, \"max\": 10}, # depth of tree\n",
        "        \"iterations\": {\"min\": 100, \"max\": 500}, # learning iteration\n",
        "        \"subsample\": {\"min\": 0.05, \"max\": 1.0},  # subsample parameter\n",
        "        \"rsm\": {\"min\": 0.05, \"max\": 1.0},        # feature sampling by level\n",
        "        \"min_data_in_leaf\": {\"min\": 1, \"max\": 100}  # minimum data in leaf\n",
        "    }\n",
        "}\n",
        "\n",
        "# create the sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"ctr-prediction\")\n",
        "\n",
        "# define the train function\n",
        "def train():\n",
        "    # initialize wandb for the current run\n",
        "    with wandb.init(config=wandb.config):\n",
        "        # get hyperparameters from the wandb.config object that includes parameter values\n",
        "        learning_rate = wandb.config.learning_rate\n",
        "        depth = wandb.config.depth\n",
        "        iterations = wandb.config.iterations\n",
        "        subsample = wandb.config.subsample\n",
        "        rsm = wandb.config.rsm\n",
        "        min_data_in_leaf = wandb.config.min_data_in_leaf\n",
        "\n",
        "        # create CatBoost model with the current hyperparameters\n",
        "        model = CatBoostClassifier(\n",
        "            learning_rate=learning_rate,\n",
        "            depth=depth,\n",
        "            iterations=iterations,\n",
        "            cat_features=cat_features,  # add your categorical feature indices here\n",
        "            early_stopping_rounds=10,  # stop if the validation loss doesn't improve for 10 rounds\n",
        "            use_best_model=True,  # enable early stopping using the best model\n",
        "            subsample=subsample,\n",
        "            rsm=rsm,\n",
        "            min_data_in_leaf=min_data_in_leaf,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # train the model\n",
        "        model.fit(X_train, y_train, eval_set=(X_valid, y_valid))\n",
        "\n",
        "        # calculate the average training loss\n",
        "        train_preds = model.predict_proba(X_train)\n",
        "        average_train_loss = log_loss(y_train, train_preds) #cross-entropy loss\n",
        "\n",
        "        # calculate the average validation loss\n",
        "        valid_preds = model.predict_proba(X_valid)\n",
        "        average_valid_loss = log_loss(y_valid, valid_preds) #cross-entropy loss\n",
        "\n",
        "        # log average losses to the W&B\n",
        "        wandb.log({\"average_train_loss\": average_train_loss, \"average_valid_loss\": average_valid_loss})\n",
        "\n",
        "        # make predictions on the validation set\n",
        "        y_valid_pred = model.predict(X_valid)\n",
        "\n",
        "        # calculate and log accuracy, precision, recall, and F1-score for validation set\n",
        "        accuracy = accuracy_score(y_valid, y_valid_pred)\n",
        "        precision = precision_score(y_valid, y_valid_pred)\n",
        "        recall = recall_score(y_valid, y_valid_pred)\n",
        "        f1 = f1_score(y_valid, y_valid_pred)\n",
        "\n",
        "        # log the scores\n",
        "        wandb.log({\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1})\n",
        "\n",
        "# run the sweep\n",
        "wandb.agent(sweep_id, train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ78uMAKSiyX"
      },
      "source": [
        "### Learning Rate Scheduler\n",
        "\n",
        "Using a learning rate scheduler can be beneficial for training machine learning models, including CatBoost models, as it can help improve convergence and potentially lead to better performance. However, CatBoost already has a built-in learning rate reduction strategy based on early stopping, so you need to consider the trade-offs and your specific use case, no need explicit code for this.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17wZpm-gSiyY"
      },
      "source": [
        "### Epochs or Iteration\n",
        "\n",
        "In CatBoost, the concept of \"epochs\" isn't explicitly used in the same way it might be in some other machine learning algorithms like neural networks. CatBoost is a gradient boosting algorithm that builds an ensemble of decision trees iteratively. Instead of epochs, CatBoost uses the term \"iterations\" to refer to the number of boosting rounds during which new trees are added to the ensemble.\n",
        "\n",
        "Each iteration in CatBoost corresponds to the creation of a new decision tree. The algorithm focuses on minimizing the loss function by iteratively adding trees that correct the mistakes of the previous ones. This process continues until the specified number of iterations is reached or until early stopping criteria are met.\n",
        "\n",
        "CatBoost has built-in mechanisms to handle early stopping, which allows the algorithm to automatically stop adding trees when the performance on the validation set starts to degrade. You can specify the number of iterations when creating a CatBoost model, and you can also set early stopping criteria such as the number of rounds without improvement in validation loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHkoUiCiSiyY"
      },
      "source": [
        "### Loss Function\n",
        "\n",
        "The cross-entropy loss function is generally suitable for click-through rate (CTR) prediction tasks, including in the training section of CatBoost. The cross-entropy loss is a common choice for binary classification problems like CTR prediction, where the target variable has two classes (clicked or not clicked). Also, the cross-entropy loss is well-suited for imbalanced datasets as it penalizes misclassifying the minority class more heavily, helping the model focus on the class of interest. Our dataset is also an imbalanced dataset.\n",
        "\n",
        "Of course, there are other loss functions like (MSE) Loss, SVM Loss, etc.\n",
        "\n",
        "If you don't explicitly specify a loss function, CatBoost will automatically choose an appropriate default loss function based on the problem type. So, the default loss function for classification problems in CatBoost is typically Logloss. This loss function is commonly used for binary and multiclass classification tasks in Catboost automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcrCrU41SiyZ"
      },
      "source": [
        "### Performance Metrics\n",
        "\n",
        "Performance metrics accuracy, precision, recall, and F1 score are checked on the validation dataset, which has data in the same format as in the training dataset, but it is only used for evaluating the quality of training (it is not used for training). These can also be calculated for the test set.\n",
        "\n",
        "* **Accuracy**: is a measure of the overall correctness of the model's predictions. It can be useful for a balanced dataset, but in this study, we don't have a balanced dataset. So using only accuracy won't be a good approach.\n",
        "* **Precision**: is a metric that measures the accuracy of positive predictions made by the model. Precision is valuable when you want to minimize false positives. In our case (CTR prediction), high precision means that when the model predicts a click with the minimum number of saying the non-clicks as clicks.\n",
        "* **Recall**: (or sensitivity) measures the ability of the model to correctly identify all relevant instances (true positives). In this case, it's a really important metric, because all actual positives (clicks) should be detected in the right way. If you predict right-click values, so you can predict accurately which advertisements or content items are more likely to be clicked by users.\n",
        "* **F1 score**:  is the harmonic mean of precision and recall. It is useful when you want to balance precision and recall.\n",
        "\n",
        "\n",
        "So, choosing the best metrics to choose the best model depends on what you want. For example, If you want to focus on minimizing false positives (to avoid wasted ad spend on non-clicks), prioritize precision. If you want to ensure that you capture as many actual clicks as possible (e.g., to maximize click-through rate), prioritize recall. The recall score makes much sense for this purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqbznuTRSiya"
      },
      "source": [
        "### Compare Model Performance and Stopping Criteria\n",
        "\n",
        "Before the model development process, the baseline model should be detected to see the main model performances according to the baseline model. For example, for this study, logistic regression can be more easier algorithm agains to the other gradient boosting algorithms and it can be detected as a baseline to develop different models with higher performance.\n",
        "\n",
        "On the other hand, according to the use case or business needs, the performance criteria should be detected (for example recall should reach 0.5) before model development. Especially, each model should have a stopping criteria due to the computational restrictions. For this case, the stopping criteria depending on performance score were not determined, the training part runs until you externally stop it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGnmF4gGSiyb"
      },
      "source": [
        "### Weight&Bias Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPMEYsLBSiyb"
      },
      "source": [
        "W&B enhances the efficiency, transparency, and collaboration aspects of a CTR prediction study. It enables researchers and data scientists to streamline the model development process, experiment with different configurations, and gain valuable insights into model behavior and performance. Additionally, it promotes best practices in reproducibility and collaboration, which are crucial in data-driven research projects. Because of this, it has gained popularity nowadays.\n",
        "\n",
        "Let's analyze the results of this study inside the W&B website."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QYyTZssSiyc"
      },
      "source": [
        "Each running of the previous code section is a different sweep, so each try is saved and listed as you can see below. I've run 2 sweeps mainly, other sweeps are deleted to remove unnecessary tuning. But the most recent sweep will be taken into account to evaluate the performance metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8QHwteoSiyc"
      },
      "source": [
        "![each try.png](<attachment:each try.png>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfevHKPXSiyd"
      },
      "source": [
        "You can see the main screen which includes all runs inside the parameter tuning process. Each row represents a model with different parameters. You can track the models from this screen easily."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYqLbFgeSiyd"
      },
      "source": [
        "![runs.png](attachment:runs.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flRyBWQ9Siyd"
      },
      "source": [
        "So,  you can check logged performance scores for each model on this screen, and you can filter and sort according to metrics. For example, the following screen is sorted by recall value in descending order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o70UkOBNSiyd"
      },
      "source": [
        "![sweep list.png](<attachment:sweep list.png>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuStYu4VSiyf"
      },
      "source": [
        "If you consider the recall, the icy-sweep-322 has the best recall score relative to the other runs. You can save this model in the tuning, or you can get the value of the parameter from this table and run the algorithm again with these parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rQCA8IrSiyf"
      },
      "source": [
        "If you want to see the relationship between the parameters, W&B helps to visualize and create a report easily. For example, you can see the scatter plot validation loss, depth, and iteration. As mentioned above, minimum loss values were obtained from the high depth and iterations, which means that there can be the possibility of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiqSjzUiSiyg"
      },
      "source": [
        "![graphs.png](attachment:graphs.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs_TbuHISiyi"
      },
      "source": [
        "If you want to see the importance of the hyperparameters on the model performance, the W&B provides this info. You can find the table below, so the most important parameter which has the most effect on the model performance is 'subsample'. If the correlation is red, the parameter affects the performance in a reverse way. The second important factor is the learning rate (no surprise), so it should be tuned carefully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHygbtq4Siyj"
      },
      "source": [
        "![importance.png](attachment:importance.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMFGTPHpSiyj"
      },
      "source": [
        "By creating a parallel coordinate graph, you can try to find the effect of the parameters on the loss or other results. You can find the example below, but it's hard to say such as high depth value decreases loss. But it's a good graph to see the obvious effects of parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdbX4OfFSiyk"
      },
      "source": [
        "![parameter effect.png](<attachment:parameter effect.png>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ_5Cya5Siyy"
      },
      "source": [
        "# OVERALL RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjTEqlG1Siyz"
      },
      "source": [
        "As a result of the training process, we couldn't get good recall results. The reason probably is using the imbalanced dataset. Also if we had used the whole dataset, we'd get more good results. But it's not the main purpose of this study, and computational power is the main restriction for this study.\n",
        "\n",
        "But if you want to improve the performance;\n",
        "* You can use more data and a more balanced dataset. Or you can try techniques like oversampling the minority class, undersampling the majority class, or using synthetic data generation methods to balance the dataset.\n",
        "* You can continue fine-tuning the model's hyperparameters. Focus on optimizing for the best trade-off between precision and recall.\n",
        "* As another choice, you can consider trying different algorithms or ensemble methods/algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGIFjxWeSiy0"
      },
      "source": [
        "**THANK YOU!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}